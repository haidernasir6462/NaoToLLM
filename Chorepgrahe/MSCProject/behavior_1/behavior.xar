<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.ald.softbankrobotics.com/schema/choregraphe/project.xsd" xar_version="3">
  <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
    <bitmap>media/images/box/root.png</bitmap>
    <script language="4">
      <content>
        <![CDATA[]]>
      </content>
    </script>
    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
    <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
    <Timeline enable="0">
      <BehaviorLayer name="behavior_layer1">
        <BehaviorKeyframe name="keyframe1" index="1">
          <Diagram>
            <Box name="SendAndReceiveText" id="5" localization="8" tooltip="" x="325" y="277">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.prompt = ""  # Initialize an empty string for the prompt

    def onLoad(self):
        pass  # Initialization code if needed

    def onUnload(self):
        pass  # Cleanup code if needed

    def onInput_onStart(self):
        # Store a prompt and send it to the next box
        self.prompt = "why is sky blue? give me one line answer"  # Replace with your desired prompt
        self.output_1(self.prompt)  # Send the prompt to the next box through output_1
        self.onStopped(self)  # Notify that the box has finished its task

    def onInput_onStop(self):
        self.onUnload()  # Clean up when stopping
        self.onStopped()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="0" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
              <Output name="output_1" type="3" type_size="1" nature="2" inner="0" tooltip="" id="5" />
            </Box>
            <Box name="LLM_Response" id="2" localization="8" tooltip="Say the text received on its input." x="666" y="270">
              <bitmap>media/images/box/interaction/say.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import requests
from naoqi import ALProxy
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        # Initialization code
        self.tts = ALProxy("ALTextToSpeech")  # Use TTS to speak messages

    def onUnload(self):
        # Clean-up code
        pass

    def onInput_onStart(self, p):
        print("Starting to send request...")
        prompt= str(p)
        self.tts.say(prompt)
        try:
            # Define the URL of the Ollama server API
            url = 'http://192.168.203.153:11434/api/generate'

            # Define the payload (you can customize this based on your API)
            payload = {
                "model": "llama3.1",
                'prompt': prompt
            }

            # Test if the requests module works
            self.tts.say("Sending request to server")

            # Send the request to the Ollama server
            response = requests.post(url, json=payload, stream=False)

            if response.status_code == 200:

                full_response = ""
                # Parse the JSON response, extract the actual response
                raw_data = response.text.strip().splitlines()
                for item in raw_data:
                    parsed_item = json.loads(item)
                    response_value = parsed_item.get('response')
                    response_value += " "
                    full_response += response_value  # Accumulate the text

                self.tts.say(str(full_response))

            else:
                self.tts.say("Failed to fetch a response. Status code: " + str(response.status_code))

        except Exception as e:
            # Catching any exception and reporting it using TTS
            error_message = "Exception: {0}".format(str(e))
            print(error_message)  # Log the error message for debugging
            self.tts.say(error_message)

        # Activate the output of the box
        self.onStopped()

    def onInput_onStop(self):
        self.onUnload()  # Clean-up when the box is stopped
        self.onStopped()  # Activate the output of the box]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
              <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
              <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
              <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
              <Resource name="Speech" type="Lock" timeout="0" />
            </Box>
            <Box name="Listener" id="1" localization="8" tooltip="" x="258" y="82">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import os
import time
from naoqi import ALProxy

class MyClass(GeneratedClass):
    def _init_(self):
        GeneratedClass._init_(self)

    def onLoad(self):
        # Initialization code
        self.tts = ALProxy("ALTextToSpeech")
        self.audio_recorder = ALProxy("ALAudioRecorder")
        self.audio_player = ALProxy("ALAudioPlayer")  # Proxy for playing the recorded audio
        self.audio_path = "/home/nao/recordings/microphones/test.wav"  # Path to save the recorded audio

    def onUnload(self):
        # Clean-up code
        pass

    def onInput_onStart(self):
        # Start recording audio
        self.tts.say("I'm listening. Please speak.")
        self.startRecording()

        # Wait for 5 seconds (or you can implement a better method to detect the end of speech)
        time.sleep(5)

        # Stop recording
        self.tts.say("Recording complete.")
        self.stopRecording()

        # NAO speaks and plays back the recorded audio
        self.tts.say("I will now play what you said.")
        self.playRecordedAudio()

        # Activate the output of the box
        self.onStopped()

    def startRecording(self):
        """Start the audio recording."""
        channels = [0, 0, 1, 0]  # Enable only the front microphone
        self.audio_recorder.startMicrophonesRecording(self.audio_path, "wav", 16000, channels)

    def stopRecording(self):
        """Stop the audio recording."""
        self.audio_recorder.stopMicrophonesRecording()

    def playRecordedAudio(self):
        """Play the recorded audio using NAO's speakers."""
        try:
            self.audio_player.playFile(self.audio_path)  # Play the recorded WAV file
        except Exception as e:
            error_message = "Error playing the recorded audio: {0}".format(str(e))
            print(error_message)
            self.tts.say(error_message)

    def onInput_onStop(self):
        self.onUnload()
        self.onStopped()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
            </Box>
            <Box name="Speech Reco." id="3" localization="8" tooltip="Recognize a word from a list of words set in the box parameters.&#x0A;&#x0A;V1.1.0&#x0A;" x="481" y="499">
              <bitmap>media/images/box/interaction/ear.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        try:
            self.asr = self.session().service("ALSpeechRecognition")
        except Exception as e:
            self.asr = None
            self.logger.error(e)
        self.memory = self.session().service("ALMemory")
        from threading import Lock
        self.bIsRunning = False
        self.mutex = Lock()
        self.hasPushed = False
        self.hasSubscribed = False
        self.BIND_PYTHON(self.getName(), "onWordRecognized")

    def onUnload(self):
        from threading import Lock
        self.mutex.acquire()
        try:
            if (self.bIsRunning):
                if (self.hasSubscribed):
                    self.memory.unsubscribeToEvent("WordRecognized", self.getName())
                if (self.hasPushed and self.asr):
                    self.asr.popContexts()
        except RuntimeError, e:
            self.mutex.release()
            raise e
        self.bIsRunning = False;
        self.mutex.release()

    def onInput_onStart(self):
        from threading import Lock
        self.mutex.acquire()
        if(self.bIsRunning):
            self.mutex.release()
            return
        self.bIsRunning = True
        try:
            if self.asr:
                self.asr.pushContexts()
            self.hasPushed = True
            if self.asr:
                self.asr.setVocabulary( self.getParameter("Word list").split(';'), self.getParameter("Enable word spotting") )
            self.memory.subscribeToEvent("WordRecognized", self.getName(), "onWordRecognized")
            self.hasSubscribed = True
        except RuntimeError, e:
            self.mutex.release()
            self.onUnload()
            raise e
        self.mutex.release()

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()

    def onWordRecognized(self, key, value, message):
        if(len(value) > 1 and value[1] >= self.getParameter("Confidence threshold (%)")/100.):
            self.wordRecognized(value[0]) #~ activate output of the box
        else:
            self.onNothing()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
              <Output name="wordRecognized" type="3" type_size="1" nature="2" inner="0" tooltip="Word recognized with a confidence higher than the threshold set in the box parameters." id="5" />
              <Output name="onNothing" type="1" type_size="1" nature="2" inner="0" tooltip="Nothing has been understood." id="6" />
              <Parameter name="Word list" inherits_from_parent="0" content_type="3" value="yes;no" default_value="yes;no" custom_choice="0" tooltip="Try to recognize a word from a list of words set in the box parameters." id="7" />
              <Parameter name="Confidence threshold (%)" inherits_from_parent="0" content_type="1" value="30" default_value="30" min="0" max="100" tooltip="If the confidence associated with the word recognized is below this threshold, the robot will consider that it is not recognized." id="8" />
              <Parameter name="Enable word spotting" inherits_from_parent="0" content_type="0" value="0" default_value="0" tooltip="If this option is not activated the robot will only understand exact expressions. If it is, he will spot the exact expressions even in the middle of a sentence.&#x0A;&#x0A;!!Warning!! This option is only available with the speech recognition module using Nuance (ie in Atom version of the robot)." id="9" />
              <Resource name="Speech recognition" type="Lock" timeout="0" />
            </Box>
            <Box name="SpeechToTextConverter" id="4" localization="8" tooltip="" x="549" y="90">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[import speech_recognition as sr

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.audio_file_path = 'path/to/your/audiofile.wav'  # Define the path to your audio file

    def onLoad(self):
        # Initialization code
        pass

    def onUnload(self):
        # Clean-up code
        pass


    def access_recorded_audio(self):
        # Open and read the recorded file
        try:
            with open(self.audio_file_path, 'rb') as audio_file:
                audio_data = audio_file.read()
                # Do something with the audio data (e.g., analyze it)
                print("Successfully accessed the recorded audio.")
                # Example: print first 100 bytes (if it's not too large)
                print(audio_data[:100])
        except IOError as e:
            print("Failed to access the recorded audio file: {0}".format(e))
    def audio_to_text(self):
        # Initialize recognizer
        recognizer = sr.Recognizer()

        try:
            # Load audio file
            with sr.AudioFile(self.audio_file_path) as source:
                audio = recognizer.record(source)

            # Recognize speech using Google Web Speech API
            text = recognizer.recognize_google(audio)
            return text

        except sr.UnknownValueError:
            return "Google Web Speech API could not understand the audio"
        except sr.RequestError as e:
            return "Could not request results from Google Web Speech API; {0}".format(e)
        except Exception as e:
            return "An error occurred: {0}".format(e)

    def onInput_onStart(self):
        # Process the audio and print the text
        text = self.audio_to_text()
        print("Converted Text:", text)
        # Activate the output of the box
        # self.onStopped() # Uncomment this if needed

    def onInput_onStop(self):
        self.onUnload()  # Reuse the clean-up as the box is stopped
        self.onStopped()  # Activate the output of the box]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
            </Box>
            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="5" />
          </Diagram>
        </BehaviorKeyframe>
      </BehaviorLayer>
    </Timeline>
  </Box>
</ChoregrapheProject>
